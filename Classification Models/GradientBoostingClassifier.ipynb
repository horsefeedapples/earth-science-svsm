{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 70 #display 70 dpi in Jupyter Notebook, may consider100 dpi \n",
    "plt.rcParams['savefig.dpi'] = 70 #define 300 dpi for saving figures\n",
    "\n",
    "import seaborn as sns\n",
    "## here are some settings \n",
    "sns.set_style('whitegrid')\n",
    "sns.set(rc={\"figure.dpi\":70, 'savefig.dpi':70}) #defining dpi setting\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "# Tells matplotlib to display images inline instead of a new window\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "\n",
    "from time import time\n",
    "import timeit #imports timeit module\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import neighbors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../RiverRoad_Quan_RF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBC(X, y, gridid):\n",
    "    start_time = timeit.default_timer()\n",
    "    kf = KFold(n_splits=5, random_state=2, shuffle=True)\n",
    "    acc_score = [];\n",
    "    Truth = [];\n",
    "    Output = [];\n",
    "    GRID_ID = pd.DataFrame(columns=['GRID_ID'])\n",
    "\n",
    "    for train_index , test_index in tqdm(kf.split(df)):\n",
    "        X_train , X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train , y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        train_grid = gridid.iloc[train_index]\n",
    "        test_grid= gridid.iloc[test_index]\n",
    "\n",
    "        model =  GradientBoostingClassifier(n_estimators = 500, \n",
    "                                               learning_rate = 0.1, \n",
    "                                               max_depth = 4, \n",
    "                                               random_state = 2)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_values = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, pred_values)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "        GRID_ID = pd.merge(GRID_ID, test_grid, on='GRID_ID', how='outer')\n",
    "        Truth.extend(y_test.values.reshape(y_test.shape[0])); ## it is a list\n",
    "        Output.extend(pred_values);\n",
    "\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    accuracy = np.mean(acc_score)\n",
    "    \n",
    "    output_df = pd.concat([GRID_ID, pd.DataFrame(Truth, columns=[\"Truth\"]), pd.DataFrame(Output, columns=[\"Output\"])], axis=1)\n",
    "    return output_df, elapsed, confusion_matrix(Truth, Output), classification_report(Truth, Output), acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBC with all 60 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [08:35, 103.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515.5195967000036 seconds\n",
      "[0.9297736506094022, 0.9332171893147503, 0.9210220673635308, 0.924506387921022, 0.9221835075493612]\n",
      "0.9261405605516131 accuracy\n",
      "[[2716  428]\n",
      " [ 208 5259]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.90      3144\n",
      "           1       0.92      0.96      0.94      5467\n",
      "\n",
      "    accuracy                           0.93      8611\n",
      "   macro avg       0.93      0.91      0.92      8611\n",
      "weighted avg       0.93      0.93      0.93      8611\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['GRID_ID', 'wetland_type', 'wetland', 'FID_RiverRd_AOI'], axis=1)\n",
    "y = df.FID_RiverRd_AOI\n",
    "gridid = df.GRID_ID\n",
    "output_df_60, time_60, cm_60, cr_60, acc_60 = GBC(X, y, gridid)\n",
    "print(f\"{time_60} seconds\")\n",
    "print(f\"{acc_60}\")\n",
    "print(f\"{np.mean(acc_60)} accuracy\")\n",
    "print(cm_60)\n",
    "print(cr_60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBC with Asami's 24 columns(Interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [03:29, 41.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209.46582929999568 seconds\n",
      "[0.9361578641903656, 0.929732868757259, 0.9303135888501742, 0.9256678281068524, 0.9320557491289199]\n",
      "0.9307855798067143 accuracy\n",
      "[[2735  409]\n",
      " [ 187 5280]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90      3144\n",
      "           1       0.93      0.97      0.95      5467\n",
      "\n",
      "    accuracy                           0.93      8611\n",
      "   macro avg       0.93      0.92      0.92      8611\n",
      "weighted avg       0.93      0.93      0.93      8611\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['qu_dsm_MAX',\n",
    "'qu_hyddem_MIN',\n",
    "'qu_dsm_MIN',\n",
    "'qu_smdem_MAX',\n",
    "'qu_dem_MIN',\n",
    "'qu_dsm_SUM',\n",
    "'qu_dsm_MEAN',\n",
    "'qu_dsm_RANGE',\n",
    "'qu_dsm_STD',\n",
    "'qu_floAcu_MAX',\n",
    "'qu_floAcu_STD',\n",
    "'qu_hyddem_MAX',\n",
    "'qu_dem_MAX',\n",
    "'qu_floAcu_RANGE',\n",
    "'qu_curpl_SUM',\n",
    "'qu_hyddem_SUM',\n",
    "'qu_curpl_MEAN',\n",
    "'qu_hyddem_MEAN',\n",
    "'qu_floAcu_MEAN',\n",
    "'qu_curpl_STD',\n",
    "'qu_floAcu_SUM',\n",
    "'qu_smdem_MIN',\n",
    "'qu_smdem_SUM',\n",
    "'qu_curv_STD',\n",
    "]\n",
    "X = df[columns]\n",
    "y = df.FID_RiverRd_AOI\n",
    "gridid = df.GRID_ID\n",
    "output_df_24, time_24, cm_24, cr_24, acc_24 = GBC(X, y, gridid)\n",
    "print(f\"{time_24} seconds\")\n",
    "print(f\"{acc_24}\")\n",
    "print(f\"{np.mean(acc_24)} accuracy\")\n",
    "print(cm_24)\n",
    "print(cr_24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBC with Asami's 12 columns(Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:43, 20.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.34160079999128 seconds\n",
      "[0.934997098084736, 0.9285714285714286, 0.929732868757259, 0.9227642276422764, 0.9303135888501742]\n",
      "0.9292758423811748 accuracy\n",
      "[[2734  410]\n",
      " [ 199 5268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      3144\n",
      "           1       0.93      0.96      0.95      5467\n",
      "\n",
      "    accuracy                           0.93      8611\n",
      "   macro avg       0.93      0.92      0.92      8611\n",
      "weighted avg       0.93      0.93      0.93      8611\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "'qu_dsm_MAX',\n",
    "'qu_hyddem_MIN',\n",
    "'qu_dsm_MIN',\n",
    "'qu_smdem_MAX',\n",
    "'qu_dem_MIN',\n",
    "'qu_dsm_SUM',\n",
    "'qu_dsm_STD',\n",
    "'qu_floAcu_MAX',\n",
    "'qu_floAcu_STD',\n",
    "'qu_curpl_SUM',\n",
    "'qu_curpl_STD',\n",
    "'qu_floAcu_SUM',\n",
    "]\n",
    "X = df[columns]\n",
    "y = df.FID_RiverRd_AOI\n",
    "gridid = df.GRID_ID\n",
    "output_df_12, time_12, cm_12, cr_12, acc_12 = GBC(X, y, gridid)\n",
    "print(f\"{time_12} seconds\")\n",
    "print(f\"{acc_12}\")\n",
    "print(f\"{np.mean(acc_12)} accuracy\")\n",
    "print(cm_12)\n",
    "print(cr_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_60.to_csv(\"../Comparison Data/GBC60.csv\", index=False)\n",
    "output_df_24.to_csv(\"../Comparison Data/GBC24.csv\", index=False)\n",
    "output_df_12.to_csv(\"../Comparison Data/GBC12.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
